import pandas as pd
import lightgbm as lgb
from pathlib import Path
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# ===============================
# 1ï¸âƒ£ è¨­å®šæª”æ¡ˆè·¯å¾‘
# ===============================
DATA_DIR = Path("dataset/processed_data/merge_market_and_weather_after_engineering/Kai-lan")
TRAIN_FILE = DATA_DIR / "train_Kai-lan_after_engineering.csv"
VALID_FILE = DATA_DIR / "valid_Kai-lan_after_engineering.csv"
TEST_FILE = DATA_DIR / "test_Kai-lan_after_engineering.csv"
output_dir = Path("dataset/model/Kai-lan")
output_dir.mkdir(parents=True, exist_ok=True)

TARGET_COL = "åƒ¹æ ¼(å…ƒ/å…¬æ–¤)"

# ===============================
# 2ï¸âƒ£ è®€å–è³‡æ–™
# ===============================
train_df = pd.read_csv(TRAIN_FILE)
valid_df = pd.read_csv(VALID_FILE)
test_df = pd.read_csv(TEST_FILE)

# ===============================
# 3ï¸âƒ£ åˆ†ç‰¹å¾µèˆ‡ç›®æ¨™
# ===============================
feature_cols = [c for c in train_df.columns if c != "æ—¥æœŸ" and c != TARGET_COL]

X_train, y_train = train_df[feature_cols], train_df[TARGET_COL]
X_valid, y_valid = valid_df[feature_cols], valid_df[TARGET_COL]
X_test, y_test = test_df[feature_cols], test_df[TARGET_COL]

# ===============================
# 4ï¸âƒ£ å»ºç«‹ LightGBM Dataset
# ===============================
lgb_train = lgb.Dataset(X_train, y_train)
lgb_valid = lgb.Dataset(X_valid, y_valid, reference=lgb_train)

# ===============================
# 5ï¸âƒ£ è¨­å®šåƒæ•¸
# ===============================
params = {
    "objective": "regression",
    "metric": "rmse",
    "boosting_type": "gbdt",
    "learning_rate": 0.05,
    "num_leaves": 31,
    "max_depth": -1,
    "verbose": -1
}

# ===============================
# 6ï¸âƒ£ è¨“ç·´æ¨¡å‹
# ===============================
gbm = lgb.train(
    params,
    lgb_train,
    num_boost_round=1000,
    valid_sets=[lgb_train, lgb_valid],
    valid_names=["train", "valid"],
    callbacks=[lgb.early_stopping(stopping_rounds=50)]
)

# ===============================
# 7ï¸âƒ£ æ¸¬è©¦èˆ‡å¤šæŒ‡æ¨™è©•ä¼°
# ===============================
y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)

# è¨ˆç®—æŒ‡æ¨™
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("\n" + "="*30)
print("ğŸ“Š æ¨¡å‹è©•ä¼°å ±è¡¨ (Test Set)")
print("="*30)
print(f"MSE  (å‡æ–¹èª¤å·®): {mse:.4f}")
print(f"RMSE (å‡æ–¹æ ¹èª¤å·®): {rmse:.4f}")
print(f"MAE  (å¹³å‡çµ•å°èª¤å·®): {mae:.4f}")
print(f"RÂ²   (åˆ¤å®šä¿‚æ•¸): {r2:.4f}")
print("="*30)

# ===============================
# 8ï¸âƒ£ è¦–è¦ºåŒ–æ¯”è¼ƒåœ–
# ===============================
plt.figure(figsize=(12, 6))
plt.plot(y_test.values, label="Actual Price", color="blue", alpha=0.7)
plt.plot(y_pred, label="Predicted Price", color="red", linestyle="--", alpha=0.8)
plt.title(f"Kai-lan Price Prediction (RÂ²: {r2:.3f})")
plt.xlabel("Sample Index (Time Sequence)")
plt.ylabel("Price (NTD/kg)")
plt.legend()
plt.grid(True)
plt.show()

# ===============================
# 9ï¸âƒ£ å„²å­˜æ¨¡å‹
# ===============================
MODEL_FILE = output_dir / "lgb_model_Kai-lan.txt"
gbm.save_model(str(MODEL_FILE))
print(f"\nâœ… æ¨¡å‹å·²å„²å­˜è‡³ {MODEL_FILE}")